# Search-R1 + Qwen3-0.6b 训练配置文件
# 此文件用于集中管理训练参数，使配置更加清晰和易于维护

# 模型配置
model:
  # HuggingFace 模型名称或本地路径
  base_model: "Qwen/Qwen3-0.6B"
  # 如果使用本地模型，修改为本地路径
  # base_model: "../models/Qwen3-0.6B"

  # 模型优化选项
  enable_gradient_checkpointing: true
  use_remove_padding: true

# 数据配置
data:
  # 数据文件路径
  train_file: "../data/sample_train.jsonl"
  test_file: "../data/sample_train.jsonl"

  # 数据处理参数
  train_batch_size: 32
  val_batch_size: 16
  max_prompt_length: 2048
  max_response_length: 256
  max_start_length: 1024
  max_obs_length: 256
  shuffle_train_dataloader: true

# 训练配置
training:
  # 实验信息
  experiment_name: "search-r1-qwen3-0.6b-demo"
  wandb_project: "Search-R1-Demo"

  # GPU 配置
  cuda_visible_devices: "0"  # 可以设置为 "0,1,2,3" 使用多个GPU
  n_gpus_per_node: 1
  nnodes: 1

  # 训练参数
  total_epochs: 5
  total_training_steps: 100
  save_freq: 50          # 每50步保存一次检查点
  test_freq: 25          # 每25步进行一次验证

  # 学习率
  learning_rate: 5.0e-6
  lr_warmup_steps_ratio: 0.1

  # KL 散度损失
  use_kl_loss: true
  kl_loss_coef: 0.001
  kl_loss_type: "low_var_kl"

  # 批次大小
  ppo_mini_batch_size: 16
  ppo_micro_batch_size: 4

# 算法配置
algorithm:
  # 使用 GRPO 算法（适合小模型）
  adv_estimator: "grpo"
  no_think_rl: false

# Rollout 配置
rollout:
  name: "vllm"
  n_agent: 3
  temperature: 0.8
  tensor_model_parallel_size: 1
  gpu_memory_utilization: 0.5
  log_prob_micro_batch_size: 8

# 参考模型配置
reference:
  log_prob_micro_batch_size: 8

# FSDP 配置（分布式训练）
fsdp:
  param_offload: false
  grad_offload: false
  optimizer_offload: false

# 检索器配置
retriever:
  url: "http://127.0.0.1:8000/retrieve"
  topk: 3

# 对话配置
dialogue:
  max_turns: 2

# 日志和监控
logging:
  # WandB 模式: online, offline, disabled
  wandb_mode: "offline"
  logger_types:
    - "wandb"

# 输出目录
output:
  checkpoint_dir: "../checkpoints"
  log_dir: "../logs"

# 环境变量（可选，也可以通过 .env 文件设置）
# 这里的设置会被 .env 文件中的同名变量覆盖
environment:
  CUDA_VISIBLE_DEVICES: "0"
  WANDB_MODE: "offline"
  # WANDB_API_KEY: "your_api_key_here"  # 不要在此文件中保存密钥！
